# ðŸš€ 30-Day ML/AI Interview Mastery Program

*Complete study-plus-build curriculum for mastering Machine Learning and AI concepts with mathematical rigor*

## 0. Orientation (Tonight, 6 Aug)

| What                 | How                                                                                        | Output                                                                                                   |
| -------------------- | ------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------- |
| **Baseline package** | 30â€‘item Google Form (math, coding, ML theory); 10â€‘min live chat to set goals & constraints | *Gap matrix* (I'll tag every topic 0 â€“ 5) + **Personal Roadâ€‘Signs** PDF: which remedial pods to activate |
| **Repo skeleton**    | GitHub template with branchâ€‘perâ€‘topic, preâ€‘wired pytest + nbval                            | Push test commit                                                                                         |

> **Personalisation rule:** if any section in the gap matrix scores < 3, the matching "Remedial Pod" (see legend ðŸ”§) is autoâ€‘inserted on the next available light day.

---

# ðŸ—“ï¸ 30â€‘Day Map (6 Aug â†’ 5 Sep, interview 6 Sep)

### DAILY RHYTHM  *(â‰ˆ 2 h weekday, 4 h weekend)*

| Minute | Slot                  | Method                                                        |
| ------ | --------------------- | ------------------------------------------------------------- |
| 0â€‘10   | **Spaced Repetition** | Anki deck (autoâ€‘generated from yesterday's notes)             |
| 10â€‘40  | **Math Deep Read**    | Derivation walkâ€‘through (PDF + whiteboard gif)                |
| 40â€‘85  | **Codeâ€‘Fromâ€‘Scratch** | Start in NumPy âžœ refactor to scikitâ€‘learn or PyTorch          |
| 85â€‘100 | **Interview Drill**   | 3 live questions (1 theory, 1 design, 1 "explain like I'm 5") |
| END    | **Commit + PR**       | Notebook tests must pass CI                                   |

*(Weekend blocks concatenate two daily slots; last 30 min is peer/mentor review.)*

---

## Legend of ðŸ”§ Remedial Pods (autoâ€‘inserted if score < 3)

| Pod           | Trigger            | Content                                                                    |
| ------------- | ------------------ | -------------------------------------------------------------------------- |
| **LINALGâ€‘ðŸ”§** | Linear algebra < 3 | Basis â†’ eigen, SVD, matrix calculus, 1 extra day                           |
| **MATHâ€‘P**    | Probability < 3    | Bayes, conjugate priors, likelihood vs. posterior                          |
| **DLâ€‘BOOT**   | DL < 2             | Perceptron, backâ€‘prop, ReLU, basic CNN; replaces a Genâ€‘AI Friday if needed |

---

## Week 1 â€” Math & Classical ML Foundations

| Date                       | Theme                     | Crystalâ€‘Clear Takeâ€‘aways                                                                                      | Handsâ€‘On / Eval                                     |
| -------------------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| **6 Aug**                  | Baseline & Linear Algebra | Why eigenvectors define invariant subâ€‘spaces; full derivation of SVD; *why* Xáµ€X appears in normal equation    | Ridge & OLS notebooks + quiz                        |
| **7 Aug**                  | Bayes Core                | Conjugate prior proofs; MAP vs. MLE; Laplace vs. Jeffreys smoothing math                                      | Build Gaussian & Multinomial NB; PR review          |
| **8 Aug**                  | Entropy & Trees           | Infoâ€‘Gain vs. Gini math; costâ€‘complexity pruning proof                                                        | Decisionâ€‘Tree + RF notebook; 5â€‘Q drill              |
| **9 Aug** **(Genâ€‘AI F#1)** | Tokenization              | BPE mergeâ€‘rank proof; WordPiece likelihood maximisation; UnigramLM; OOV math                                  | Write your own BPE; compare tokens across languages |
| **10â€‘11 Aug (WE)**         | Ensembles + Clustering    | Biasâ€‘variance math for bagging; AdaBoost exponential loss deriv.; EM algorithm; Voronoi intuition for kâ€‘Means | Animate kâ€‘Means & EM; 5â€‘min lightning talk video    |
| **12 Aug**                 | SVM                       | KKT conditions proof; kernel trick geometry; VCâ€‘dimension intuition                                           | Quadâ€‘prog SVM + RBF; explain misâ€‘classifications    |

---

## Week 2 â€” Deep Learning Core

| Date                            | Theme            | Crystalâ€‘Clear Takeâ€‘aways                                                                    | Handsâ€‘On / Eval                             |
| ------------------------------- | ---------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------- |
| **13 Aug**                      | NN & Backâ€‘prop   | Universal Approx. theorem; Jacobianâ€‘style backâ€‘prop; weightâ€‘init statistics                 | MLP on Fashionâ€‘MNIST; gradâ€‘check unit tests |
| **14 Aug** **(Voice Thursday)** | Audio AI         | CTC loss deriv.; Mel filterâ€‘bank math; Tacotron attention alignment                         | Wav2Vec2 ASR + Tacotron TTS Colab           |
| **15 Aug**                      | **REST/Async**   | Light reading + peer code reviews                                                           | â€”                                           |
| **16â€‘17 Aug (WE)**              | CNNâ€‘Internals    | Convolution theorem; receptive field calc; batchâ€‘norm var. deriv.; pooling invariance proof | CNN from scratch, filter viz                |
| **18 Aug**                      | RNN â†” LSTM       | Gate math, vanishingâ€‘grad proof; TBPTT cost                                                 | Biâ€‘LSTM for NER; compare GRU                |
| **19 Aug** **(Genâ€‘AI T#2)**     | Image Generative | VAE ELBO, KL tricks; GAN minâ€‘max; diffusion score match                                     | Train tiny VAE; identify mode collapse      |

---

## Week 3 â€” Transformers & LLMs

| Date                        | Theme                   | Crystalâ€‘Clear Takeâ€‘aways                                          | Handsâ€‘On / Eval                           |
| --------------------------- | ----------------------- | ----------------------------------------------------------------- | ----------------------------------------- |
| **20 Aug**                  | Attention               | âˆšd\_k scaling proof; Bahdanau vs. Luong math                      | Implement attention in NumPy              |
| **21 Aug**                  | Transformer Skeleton    | Preâ€‘norm vs. postâ€‘norm gradient math; FFN 4 Ã— size rationale      | Encoderâ€‘decoder full cycle                |
| **22 Aug** **(Genâ€‘AI F#2)** | LLM Training            | Crossâ€‘entropy; scaling laws curveâ€‘fit; gradient clipping analysis | GPTâ€‘mini (12â€‘layer) on WikiTextâ€‘2         |
| **23â€‘24 Aug (WE)**          | Fineâ€‘tuning & Alignment | LoRA matrix math; QLoRA quant; PPO, DPO derivations               | Fineâ€‘tune Alpacaâ€‘7B; reward model sandbox |
| **25 Aug**                  | Evaluations             | Perplexity pitfalls; GEMBA; BERTScore math                        | Eval script; create synthetic fail cases  |

---

## Week 4 â€” Agents, RAG & Prodâ€‘Ops

| Date                           | Theme                  | Crystalâ€‘Clear Takeâ€‘aways                                                        | Handsâ€‘On / Eval                                      |
| ------------------------------ | ---------------------- | ------------------------------------------------------------------------------- | ---------------------------------------------------- |
| **26 Aug** **(Agents Monday)** | Reasoning Agents       | ReAct loop maths; toolâ€‘calling protocol spec; chainâ€‘ofâ€‘thought entropy          | ReAct agent in LangChain; unit tests for tool errors |
| **27 Aug**                     | LangChain & RAG        | LCEL graph theory; vector vs. hybrid retrieval maths                            | Build Pinecone RAG; measure recall Î”                 |
| **28 Aug**                     | Embeddings & Retrieval | Cosine vs. dot; DPR dualâ€‘encoder loss; ColBERT MaxSim deriv.                    | Train SBERTâ€tiny; compare SPLADE                     |
| **29 Aug** **(Genâ€‘AI F#3)**    | Voice Agents           | Realâ€‘time ASR windowing math; VAD ROC tradeâ€‘off; speaker diarization clustering | WebRTC voice bot; latency report                     |
| **30â€‘31 Aug (WE)**             | MLOps                  | A/B test stats; conceptâ€drift KS test; Triton batching queue theory             | CI/CD + Prometheus dashboards                        |

---

## Final Stretch

| Date      | Theme                | Output                                                |
| --------- | -------------------- | ----------------------------------------------------- |
| **1 Sep** | Ethics & Safety      | Oneâ€‘pager cheatâ€‘sheet; scenario Q\&A                  |
| **2 Sep** | Mock Interview #1    | Full scorecard; identify red zones                    |
| **3 Sep** | Buffer / Restitution | Plug gaps flagged in scorecard                        |
| **4 Sep** | Mock Interview #2    | Systemsâ€‘design + behavioural                          |
| **5 Sep** | **Powerâ€‘Review**     | 250â€‘card Anki blitz; formula sheet; confidence ritual |
| **6 Sep** | **Interview Day**    | â€”                                                     |

---

### Builtâ€‘in Evaluation & Feedback

| Checkpoint              | Method                               | Threshold          |
| ----------------------- | ------------------------------------ | ------------------ |
| **Midâ€‘Week Quiz (Wed)** | 5 multiâ€‘part questions (autoâ€‘graded) | â‰¥ 80 % to proceed  |
| **Weekend Peer Review** | Swap notebooks with mentor (or me)   | All tests green    |
| **Mock Interviews**     | Live 105 min; graded rubric          | â‰¥ 70 % each domain |

*If a threshold isn't met, the next day becomes "Remedial Focus"; original topic shifts to the buffer day.*

---

## Framework & Tool Commitments

| Area         | Primary Stack                           | Why                                |
| ------------ | --------------------------------------- | ---------------------------------- |
| Classical ML | **scikitâ€‘learn, NumPy**                 | Breadâ€‘&â€‘butter interview libs      |
| DL + LLM     | **PyTorch + Lightning**                 | Clean Trainer/Callback API         |
| Agents & RAG | **LangChain 0.2+**                      | LCEL graphs & tool calling         |
| Voice        | **Wav2Vec2, WebRTC, Rasa**              | Industrialâ€‘strength ASR & dialogue |
| Deploy       | **FastAPI, Triton, Docker, GH Actions** | Reusable infra patterns            |

---

## Learning Assets You'll Receive

* **Daily Lesson Deck** (PDF) â€“ definition + history + derivation + alternatives
* **Whiteboard GIF** â€“ animated derivation for visual memory
* **Handsâ€‘On Notebook** â€“ NumPy baseline â†’ optimized version (sklearn/PyTorch)
* **Autoâ€‘Gen Anki Cards** â€“ every symbol, formula, hyperâ€‘parameter
* **Flashâ€‘Card Deck** â€“ "Explain X in 60 sec" prompts
* **Mock Interview Rubrics** â€“ detailed feedback per competency
* **Architecture Stencils** â€“ draw\.io templates for whiteboard questions
* **Cheatâ€‘Sheets** â€“ 1â€‘page quickâ€‘reference per major family (trees, attention, RAGâ€¦)

All assets live in the repo; CI enforces notebookâ€‘runs = âœ… and lint = âœ… before merge.

---

## Next Actions (Your Side)

1. **Confirm** that the map & rhythm fit your calendar (esp. weekends).
2. **Tell me** your preferred comms channel for daily drills.
3. Complete tonight's **Baseline package** before midnight IST so we can autoâ€‘insert any ðŸ”§ Remedial Pods by tomorrow morning.

---

## Repository Structure

```
ml-ai-interview-mastery/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ week1/
â”‚   â”œâ”€â”€ week2/
â”‚   â”œâ”€â”€ week3/
â”‚   â””â”€â”€ week4/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classical_ml/
â”‚   â”œâ”€â”€ deep_learning/
â”‚   â”œâ”€â”€ transformers/
â”‚   â””â”€â”€ agents/
â”œâ”€â”€ tests/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ lesson_decks/
â”‚   â”œâ”€â”€ whiteboard_gifs/
â”‚   â”œâ”€â”€ anki_cards/
â”‚   â””â”€â”€ cheat_sheets/
â””â”€â”€ docs/
```

## Getting Started

1. Clone this repository
2. Install dependencies: `pip install -r requirements.txt`
3. Complete the baseline assessment
4. Follow the daily curriculum starting with Week 1
5. Submit notebooks via PR for review

## License

This curriculum is designed for personal learning and interview preparation. All implementations are for educational purposes.
